{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==============================================================================\n# GPU SERVER - TRUE PARALLEL (2x SPEED) + ALL FEATURES\n# ==============================================================================\nimport subprocess\nimport sys\nimport os\nimport time\nimport uuid\nimport threading\nimport queue\nimport shutil\nimport json\nimport random\nimport math\nimport urllib.request\nimport logging\nfrom concurrent.futures import ThreadPoolExecutor\nfrom datetime import datetime, timedelta, timezone \n\n# Optimize Memory\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\n# Suppress Tokenizer Warnings\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)\n\n# ------------------------------------------\n# CONFIGURATION & CREDENTIALS\n# ------------------------------------------\nSERVER_ID = str(uuid.uuid4())[:8]\nR2_ACCOUNT_ID = \"4fa19e788a951ba2d879c18782ef8bf0\"\nR2_ACCESS_KEY_ID = \"d66adcff67ac5b4eca609a662b80e742\"\nR2_SECRET_ACCESS_KEY = \"1a10aca3049c176d85cf3ec3c4e4ae8c6b715a4d9b1e67a79acc8b94d3b3c660\"\nR2_BUCKET_NAME = \"video-generation-storage\"\nR2_ENDPOINT_URL = f\"https://{R2_ACCOUNT_ID}.r2.cloudflarestorage.com\"\n\nUPSTASH_REDIS_REST_URL = \"https://absolute-redfish-9172.upstash.io\"\nUPSTASH_REDIS_REST_TOKEN = \"ASPUAAImcDE1MzBmZjIxMGNkYzY0YzBmYjFkZTNlZmE4NzY1ZjlhN3AxOTE3Mg\"\n\n# ------------------------------------------\n# 1. DEPENDENCY CHECK\n# ------------------------------------------\ndef install_if_missing(package, import_name=None):\n    if import_name is None:\n        import_name = package\n    try:\n        __import__(import_name)\n    except ImportError:\n        print(f\"‚¨áÔ∏è Installing {package}...\")\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n\nif shutil.which('ffmpeg') is None:\n    print(\"Installing FFmpeg...\")\n    subprocess.run([\"apt-get\", \"update\"], stdout=subprocess.DEVNULL)\n    subprocess.run([\"apt-get\", \"install\", \"-y\", \"ffmpeg\"], stdout=subprocess.DEVNULL)\n\ninstall_if_missing(\"boto3\")\ninstall_if_missing(\"requests\")\ninstall_if_missing(\"openai-whisper\", \"whisper\")\ninstall_if_missing(\"moviepy\")\ninstall_if_missing(\"unidecode\")\ninstall_if_missing(\"Pillow\", \"PIL\")\n\ntry:\n    import diffusers\n    import transformers\n    import accelerate\n    import safetensors\nexcept ImportError:\n    print(\"‚¨áÔ∏è Installing AI Libraries...\")\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"diffusers\", \"transformers\", \"accelerate\", \"safetensors\", \"xformers\"])\n\n# ------------------------------------------\n# 2. IMPORTS\n# ------------------------------------------\nimport torch\nfrom diffusers import StableDiffusionXLPipeline, EulerDiscreteScheduler, AutoencoderTiny\nimport boto3\nfrom botocore.config import Config\nimport requests as http_requests\nimport whisper\nfrom PIL import Image, ImageFont, ImageDraw\n\n# ------------------------------------------\n# 3. FONT MANAGEMENT\n# ------------------------------------------\nFONT_DIR = \"./fonts\"\nSUBTITLE_FONTS = {}\n\nFONT_CONFIG = {\n    'latin': {\n        'file': 'NotoSans-Bold.ttf',\n        'url': 'https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSans/hinted/ttf/NotoSans-Bold.ttf',\n        'family_name': 'Noto Sans',\n        'weight': 'Bold'\n    },\n    'devanagari': {\n        'file': 'NotoSansDevanagari-Bold.ttf',\n        'url': 'https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSansDevanagari/hinted/ttf/NotoSansDevanagari-Bold.ttf',\n        'family_name': 'Noto Sans Devanagari',\n        'weight': 'Bold'\n    },\n    'arabic': {\n        'file': 'NotoSansArabic-Bold.ttf',\n        'url': 'https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSansArabic/hinted/ttf/NotoSansArabic-Bold.ttf',\n        'family_name': 'Noto Sans Arabic',\n        'weight': 'Bold'\n    },\n    'cjk': {\n        'file': 'NotoSansCJKsc-Bold.otf',\n        'url': 'https://github.com/notofonts/noto-cjk/raw/main/Sans/OTF/SimplifiedChinese/NotoSansCJKsc-Bold.otf',\n        'family_name': 'Noto Sans CJK SC',\n        'weight': 'Bold'\n    }\n}\n\ndef setup_fonts():\n    if not os.path.exists(FONT_DIR):\n        os.makedirs(FONT_DIR)\n    \n    print(\"‚¨áÔ∏è Setting up fonts for subtitles...\")\n    for script, config in FONT_CONFIG.items():\n        path = os.path.join(FONT_DIR, config['file'])\n        if not os.path.exists(path):\n            try:\n                urllib.request.urlretrieve(config['url'], path)\n            except Exception as e:\n                print(f\"‚ùå Failed to download {script} font: {e}\")\n                continue\n        \n        if os.path.exists(path):\n            SUBTITLE_FONTS[script] = path\n            print(f\"  ‚úì Loaded {script}\")\n\nsetup_fonts()\n\n# ------------------------------------------\n# 4. SUBTITLE ENGINE (CJK FIX INCLUDED)\n# ------------------------------------------\ndef detect_script(text):\n    if not text or not text.strip(): return 'latin'\n    counts = {'devanagari': 0, 'arabic': 0, 'cjk': 0, 'latin': 0}\n    for char in text:\n        code = ord(char)\n        if 0x0900 <= code <= 0x0DFF: counts['devanagari'] += 1\n        elif 0x0600 <= code <= 0x077F: counts['arabic'] += 1\n        elif 0x4E00 <= code <= 0x9FFF: counts['cjk'] += 1\n        elif 0x3040 <= code <= 0x30FF: counts['cjk'] += 1\n        else: counts['latin'] += 1\n    max_script = max(counts.items(), key=lambda x: x[1])\n    return max_script[0] if max_script[1] > 0 else 'latin'\n\ndef get_font_for_text(text):\n    script = detect_script(text)\n    mapping = {'devanagari': 'devanagari', 'arabic': 'arabic', 'cjk': 'cjk'}\n    key = mapping.get(script, 'latin')\n    if key in SUBTITLE_FONTS:\n        return SUBTITLE_FONTS[key], FONT_CONFIG[key], script\n    return SUBTITLE_FONTS.get('latin'), FONT_CONFIG.get('latin'), 'latin'\n\ndef time_to_ass(seconds):\n    h = int(seconds // 3600)\n    m = int((seconds % 3600) // 60)\n    s = int(seconds % 60)\n    cs = int((seconds % 1) * 100)\n    return f\"{h}:{m:02d}:{s:02d}.{cs:02d}\"\n\ndef calculate_text_width(text, font_path, font_size):\n    try:\n        font = ImageFont.truetype(font_path, font_size)\n        dummy = ImageDraw.Draw(Image.new(\"RGBA\", (1, 1)))\n        bbox = dummy.textbbox((0, 0), text, font=font)\n        return bbox[2] - bbox[0]\n    except:\n        return len(text) * font_size * 0.6\n\ndef create_ass_event_for_page(page_lines, font_size, events, is_cjk, is_latin):\n    if not page_lines: return\n    start_time = page_lines[0][0]['start']\n    end_time = page_lines[-1][-1]['end']\n    \n    def process_word(word_obj):\n        raw = word_obj.get('word', '').strip()\n        return raw.upper() if is_latin else raw\n    \n    separator = '' if is_cjk else ' '\n    full_text_lines = [separator.join([process_word(w) for w in line]) for line in page_lines]\n    full_text = '\\\\N'.join(full_text_lines)\n    \n    events.append(f\"Dialogue: 0,{time_to_ass(start_time)},{time_to_ass(end_time)},BG,,0,0,0,,{{\\\\bord15\\\\shad0\\\\1c&H000000&\\\\1a&H4D&}}{full_text}\")\n    \n    for line_idx, line in enumerate(page_lines):\n        for word_idx, word_obj in enumerate(line):\n            w_start = word_obj.get('start', start_time)\n            w_end = word_obj.get('end', end_time)\n            \n            highlight_lines = []\n            for l_idx, l in enumerate(page_lines):\n                line_words = []\n                for w_idx, w in enumerate(l):\n                    disp = process_word(w)\n                    if l_idx == line_idx and w_idx == word_idx:\n                        line_words.append(f\"{{\\\\bord8\\\\3c&HD30093&\\\\3a&H4D&\\\\shad2\\\\4c&H000000&\\\\4a&H00&}}{disp}{{\\\\bord0\\\\shad0}}\")\n                    else:\n                        line_words.append(disp)\n                highlight_lines.append(separator.join(line_words))\n            \n            hl_text = '\\\\N'.join(highlight_lines)\n            events.append(f\"Dialogue: 1,{time_to_ass(w_start)},{time_to_ass(w_end)},PurpleBG,,0,0,0,,{hl_text}\")\n    \n    events.append(f\"Dialogue: 2,{time_to_ass(start_time)},{time_to_ass(end_time)},Default,,0,0,0,,{full_text}\")\n    \n    for line_idx, line in enumerate(page_lines):\n        for word_idx, word_obj in enumerate(line):\n            w_start = word_obj.get('start', start_time)\n            w_end = word_obj.get('end', end_time)\n            top_lines = []\n            for l_idx, l in enumerate(page_lines):\n                line_words = []\n                for w_idx, w in enumerate(l):\n                    disp = process_word(w)\n                    if l_idx == line_idx and w_idx == word_idx:\n                        line_words.append(f\"{{\\\\c&HFFFFFF&}}{disp}\")\n                    else:\n                        line_words.append(disp)\n                top_lines.append(separator.join(line_words))\n            \n            joined_top_lines = '\\\\N'.join(top_lines)\n            events.append(f\"Dialogue: 3,{time_to_ass(w_start)},{time_to_ass(w_end)},Default,,0,0,0,,{joined_top_lines}\")\n\ndef generate_clip_ass_subtitles(subtitle_words, width, height, output_file):\n    if not subtitle_words: return False\n    \n    all_text_raw = \"\".join([w.get('word', '') for w in subtitle_words])\n    font_path, font_config, script = get_font_for_text(all_text_raw)\n    font_family = font_config['family_name']\n    \n    is_cjk = script == 'cjk'\n\n    processed_words = []\n    if is_cjk:\n        for w in subtitle_words:\n            text = w.get('word', '').strip()\n            start = w.get('start', 0)\n            end = w.get('end', 0)\n            duration = end - start\n            length = len(text)\n            \n            if length > 1:\n                char_duration = duration / length\n                for i, char in enumerate(text):\n                    char_start = start + (i * char_duration)\n                    char_end = start + ((i + 1) * char_duration)\n                    processed_words.append({'word': char, 'start': char_start, 'end': char_end})\n            elif length == 1:\n                processed_words.append(w)\n    else:\n        processed_words = subtitle_words\n\n    aspect = width / height\n    if aspect < 0.8: # 9:16\n        ref_h, ref_f, ref_pos = 1280, 63, 0.75\n        pos_offset = 0\n    elif aspect > 1.5: # 16:9\n        ref_h, ref_f, ref_pos = 720, 72, 0.85\n        pos_offset = 38\n    else: # 1:1 or 4:5\n        ref_h, ref_f, ref_pos = 1080, 68, 0.80\n        pos_offset = 0\n        \n    font_size = int(ref_f * (height / ref_h))\n    ref_position = int(height * ref_pos) + pos_offset\n    margin_v = height - ref_position\n    \n    header = f\"\"\"[Script Info]\nScriptType: v4.00+\nPlayResX: {width}\nPlayResY: {height}\nWrapStyle: 0\nScaledBorderAndShadow: yes\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Default,{font_family},{font_size},&H00FFFFFF,&H000000FF,&H00000000,&HB3000000,-1,0,0,0,100,100,0,0,1,0,0,2,20,20,{margin_v},1\nStyle: BG,{font_family},{font_size},&H00FFFFFF,&H000000FF,&H00000000,&HB3000000,-1,0,0,0,100,100,0,0,1,0,0,2,20,20,{margin_v},1\nStyle: PurpleBG,{font_family},{font_size},&H00FFFFFF,&H000000FF,&H00000000,&HB4D30093,-1,0,0,0,100,100,0,0,1,3,2,2,20,20,{margin_v},1\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n\"\"\"\n    events = []\n    \n    is_latin = script == 'latin'\n    max_line_width = width * 0.90\n    space_width = 0 if is_cjk else int(font_size * 0.25)\n    \n    current_page_lines = []\n    current_line = []\n    current_line_width = 0\n    \n    for word_obj in processed_words:\n        raw = word_obj.get('word', '').strip()\n        disp = raw.upper() if is_latin else raw\n        w_width = calculate_text_width(disp, font_path, font_size) + 10\n        \n        if current_line_width + w_width + space_width > max_line_width:\n            if current_line: current_page_lines.append(current_line)\n            if len(current_page_lines) >= 2:\n                create_ass_event_for_page(current_page_lines, font_size, events, is_cjk, is_latin)\n                current_page_lines = []\n            current_line = [word_obj]\n            current_line_width = w_width + space_width\n        else:\n            current_line.append(word_obj)\n            current_line_width += w_width + space_width\n            \n    if current_line: current_page_lines.append(current_line)\n    if current_page_lines: create_ass_event_for_page(current_page_lines, font_size, events, is_cjk, is_latin)\n    \n    with open(output_file, 'w', encoding='utf-8') as f:\n        f.write(header + \"\\n\".join(events))\n    return True\n\n# ------------------------------------------\n# 5. R2 CLIENT\n# ------------------------------------------\nprint(\"üîß Setting up R2...\")\ns3_client = boto3.client(\n    's3',\n    endpoint_url=R2_ENDPOINT_URL,\n    aws_access_key_id=R2_ACCESS_KEY_ID,\n    aws_secret_access_key=R2_SECRET_ACCESS_KEY,\n    config=Config(signature_version='s3v4'),\n    region_name='auto'\n)\nprint(\"‚úÖ R2 ready\")\n\n# ------------------------------------------\n# 6. REDIS CLIENT & HEARTBEAT\n# ------------------------------------------\nprint(\"üîß Setting up Redis...\")\n\nclass UpstashRedis:\n    def __init__(self, url, token):\n        self.url = url.rstrip('/')\n        self.token = token\n        self.headers = {\"Authorization\": f\"Bearer {token}\"}\n    \n    def set(self, key, value, ex=None):\n        try:\n            cmd = [\"SET\", key, value]\n            if ex:\n                cmd.extend([\"EX\", str(ex)])\n            response = http_requests.post(f\"{self.url}/pipeline\", headers=self.headers, json=[cmd], timeout=5)\n            return response.status_code == 200\n        except:\n            return False\n    \n    def get(self, key):\n        try:\n            response = http_requests.post(f\"{self.url}/pipeline\", headers=self.headers, json=[[\"GET\", key]], timeout=5)\n            if response.status_code == 200:\n                data = response.json()\n                return data[0].get(\"result\") if data else None\n            return None\n        except:\n            return None\n    \n    def delete(self, key):\n        try:\n            response = http_requests.post(f\"{self.url}/pipeline\", headers=self.headers, json=[[\"DEL\", key]], timeout=5)\n            return response.status_code == 200\n        except:\n            return False\n    \n    def keys(self, pattern):\n        try:\n            response = http_requests.post(f\"{self.url}/pipeline\", headers=self.headers, json=[[\"KEYS\", pattern]], timeout=5)\n            if response.status_code == 200:\n                data = response.json()\n                return data[0].get(\"result\", []) if data else []\n            return []\n        except:\n            return []\n\nredis_client = UpstashRedis(UPSTASH_REDIS_REST_URL, UPSTASH_REDIS_REST_TOKEN)\nprint(\"‚úÖ Redis ready\")\n\ndef heartbeat_worker():\n    print(\"üíì Heartbeat monitor started...\")\n    while True:\n        try:\n            check = redis_client.get(\"health_check_request\")\n            if check:\n                response_key = f\"health_response:{SERVER_ID}\"\n                redis_client.set(response_key, \"I am there\", ex=10)\n                time.sleep(2)\n            time.sleep(0.5)\n        except Exception as e:\n            print(f\"üíì Heartbeat error: {e}\")\n            time.sleep(5)\n\nthreading.Thread(target=heartbeat_worker, daemon=True).start()\n\n# ------------------------------------------\n# 7. WHISPER MODEL\n# ------------------------------------------\nprint(\"‚è≥ Loading Whisper Model on GPU...\")\nWHISPER_MODEL = whisper.load_model(\"base\", device=\"cuda\")\nprint(\"‚úÖ Whisper model loaded on GPU\")\n\n# ------------------------------------------\n# 8. TRANSCRIPTION FUNCTIONS\n# ------------------------------------------\ndef format_time_ref(seconds):\n    m = int(seconds // 60)\n    s = int(seconds % 60)\n    return f\"{m:02d}:{s:02d}\"\n\ndef create_prompts_txt(raw_result, duration):\n    try:\n        import math\n        from unidecode import unidecode\n        \n        num_clips = math.ceil(duration / 6.0)\n        bins = [\"\"] * num_clips\n        all_words = []\n        \n        INDIC_LANGS = {'hi', 'bn', 'gu', 'kn', 'ml', 'mr', 'pa', 'ta', 'te', 'ur', 'sd', 'ne'}\n        detected_lang = raw_result.get('language', 'en')\n        should_transliterate = detected_lang in INDIC_LANGS\n        \n        for segment in raw_result['segments']:\n            if 'words' in segment:\n                for w in segment['words']:\n                    w_text = unidecode(w['word']) if should_transliterate else w['word']\n                    all_words.append({'word': w_text, 'start': w['start']})\n        \n        if all_words:\n            for w in all_words:\n                start = w['start']\n                idx = int(start // 6)\n                if idx < num_clips:\n                    bins[idx] += w['word'].strip() + \" \"\n        else:\n            for segment in raw_result['segments']:\n                start = segment['start']\n                idx = int(start // 6)\n                txt = segment['text'].strip()\n                if should_transliterate:\n                    txt = unidecode(txt)\n                if idx < num_clips:\n                    bins[idx] += txt + \" \"\n        \n        lines = []\n        for i in range(num_clips):\n            start_str = format_time_ref(i * 6)\n            end_str = format_time_ref((i + 1) * 6)\n            text_content = bins[i].strip() if bins[i].strip() else \"[No speech]\"\n            lines.append(f\"[{i+1}] ({start_str} - {end_str})\")\n            lines.append(f\"Text: {text_content}\")\n            lines.append(\"\")\n            lines.append(\"-\" * 20)\n            lines.append(\"\")\n        \n        return \"\\n\".join(lines)\n        \n    except Exception as e:\n        print(f\"‚ùå Error generating prompts: {e}\")\n        return None\n\ndef create_subtitles_ass(raw_result):\n    try:\n        from unidecode import unidecode\n        INDIC_LANGS = {'hi', 'bn', 'gu', 'kn', 'ml', 'mr', 'pa', 'ta', 'te', 'ur', 'sd', 'ne'}\n        detected_lang = raw_result.get('language', 'en')\n        should_transliterate = detected_lang in INDIC_LANGS\n        \n        ass_lines = [\n            \"[Script Info]\",\n            \"Title: Generated Subtitles\",\n            \"ScriptType: v4.00+\",\n            \"WrapStyle: 0\",\n            \"ScaledBorderAndShadow: yes\",\n            \"YCbCr Matrix: None\",\n            \"\",\n            \"[V4+ Styles]\",\n            \"Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\",\n            \"Style: Default,Arial,20,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1\",\n            \"\",\n            \"[Events]\",\n            \"Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\",\n            \"\"\n        ]\n        \n        def format_ass_time(seconds):\n            h = int(seconds // 3600)\n            m = int((seconds % 3600) // 60)\n            s = int(seconds % 60)\n            cs = int((seconds % 1) * 100)\n            return f\"{h}:{m:02d}:{s:02d}.{cs:02d}\"\n        \n        for segment in raw_result['segments']:\n            start_time = format_ass_time(segment['start'])\n            end_time = format_ass_time(segment['end'])\n            text = segment['text'].strip()\n            \n            if should_transliterate:\n                text = unidecode(text)\n            \n            text = text.replace('\\\\', '\\\\\\\\').replace('\\n', '\\\\N')\n            ass_lines.append(f\"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{text}\")\n        \n        return \"\\n\".join(ass_lines)\n        \n    except Exception as e:\n        print(f\"‚ùå Error generating subtitles: {e}\")\n        return None\n\ndef transcribe_audio_on_gpu(audio_path):\n    try:\n        print(f\"üéôÔ∏è Transcribing with Whisper (GPU)...\")\n        result = WHISPER_MODEL.transcribe(audio_path, language=None, word_timestamps=True, verbose=False)\n        print(f\"‚úÖ Transcription complete: {len(result['segments'])} segments\")\n        return result\n    except Exception as e:\n        print(f\"‚ùå Transcription error: {e}\")\n        return None\n\ndef process_transcription_job(job_key, job_data):\n    try:\n        job = json.loads(job_data)\n        job_id = job['job_id']\n        audio_r2_key = job['audio_r2_key']\n        \n        print(f\"\\nüéôÔ∏è [TRANSCRIPTION] Processing: {job_id}\")\n        local_audio = f\"/tmp/audio_{job_id}.mp3\"\n        print(f\"   ‚¨áÔ∏è Downloading audio from R2...\")\n        s3_client.download_file(R2_BUCKET_NAME, audio_r2_key, local_audio)\n        \n        from moviepy.editor import AudioFileClip\n        clip = AudioFileClip(local_audio)\n        duration = clip.duration\n        clip.close()\n        \n        print(f\"   üéôÔ∏è Transcribing on GPU...\")\n        start_time = time.time()\n        result = transcribe_audio_on_gpu(local_audio)\n        \n        if not result:\n            redis_client.set(f\"transcription_failed:{job_id}\", \"Transcription failed\", ex=3600)\n            redis_client.delete(job_key)\n            os.remove(local_audio)\n            return False\n        \n        transcribe_time = time.time() - start_time\n        \n        print(f\"   üìù Generating prompts TXT...\")\n        prompts_txt = create_prompts_txt(result, duration)\n        \n        print(f\"   üìÑ Generating subtitles ASS...\")\n        subtitles_ass = create_subtitles_ass(result)\n        \n        result_json = json.dumps(result)\n        result_r2_key = f\"transcriptions/{job_id}.json\"\n        \n        print(f\"   ‚¨ÜÔ∏è Uploading transcription to R2...\")\n        s3_client.put_object(Bucket=R2_BUCKET_NAME, Key=result_r2_key, Body=result_json.encode('utf-8'), ContentType='application/json')\n        \n        prompts_r2_key = f\"transcriptions/{job_id}_prompts.txt\"\n        print(f\"   ‚¨ÜÔ∏è Uploading prompts TXT to R2...\")\n        s3_client.put_object(Bucket=R2_BUCKET_NAME, Key=prompts_r2_key, Body=prompts_txt.encode('utf-8'), ContentType='text/plain')\n        \n        subtitles_r2_key = f\"transcriptions/{job_id}_subtitles.ass\"\n        print(f\"   ‚¨ÜÔ∏è Uploading subtitles ASS to R2...\")\n        s3_client.put_object(Bucket=R2_BUCKET_NAME, Key=subtitles_r2_key, Body=subtitles_ass.encode('utf-8'), ContentType='text/plain')\n        \n        completion_data = json.dumps({\n            \"transcription_r2_key\": result_r2_key,\n            \"prompts_r2_key\": prompts_r2_key,\n            \"subtitles_r2_key\": subtitles_r2_key,\n            \"duration\": transcribe_time,\n            \"audio_duration\": duration,\n            \"segments\": len(result['segments']),\n            \"job_id\": job_id\n        })\n        \n        redis_client.set(f\"transcription_complete:{job_id}\", completion_data, ex=3600)\n        redis_client.delete(job_key)\n        os.remove(local_audio)\n        print(f\"‚úÖ [TRANSCRIPTION] Done! ‚è±Ô∏è {transcribe_time:.1f}s\")\n        return True\n        \n    except Exception as e:\n        print(f\"‚ùå [TRANSCRIPTION] Failed: {e}\")\n        redis_client.set(f\"transcription_failed:{job_id}\", str(e), ex=3600)\n        redis_client.delete(job_key)\n        return False\n\n# ------------------------------------------\n# 9. VIDEO GENERATION (UPDATED: PARALLEL DISPATCH)\n# ------------------------------------------\nSTEPS = 4\nGUIDANCE_SCALE = 2.0\n\nGPU_COUNT = torch.cuda.device_count()\ngpu_queues = [queue.Queue() for _ in range(GPU_COUNT)]\nvideo_process_queue = queue.Queue()\nresults = {} # Still used for tracking within R2 upload context if needed, but primary state is Redis\ncounter_lock = threading.Lock()\n\ndef upload_to_r2(video_bytes, job_id, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            video_key = f\"videos/single/{job_id}.mp4\"\n            s3_client.put_object(Bucket=R2_BUCKET_NAME, Key=video_key, Body=video_bytes, ContentType='video/mp4')\n            url = s3_client.generate_presigned_url('get_object', Params={'Bucket': R2_BUCKET_NAME, 'Key': video_key}, ExpiresIn=604800)\n            return url\n        except Exception as e:\n            if attempt < max_retries - 1:\n                time.sleep(2 ** attempt)\n    return None\n\ndef image_to_video_clip(image, target_width, target_height, subtitle_path=None):\n    unique_id = str(uuid.uuid4())\n    img_path = f\"temp_{unique_id}.png\"\n    vid_path = f\"output_{unique_id}.mp4\"\n\n    try:\n        image.save(img_path)\n        w = (int(target_width) // 2) * 2\n        h = (int(target_height) // 2) * 2\n        \n        zoom_curve = \"1.1+0.1*cos(2*PI*on/180)\"\n        filter_chain = (\n            f\"scale={w}:{h}:flags=lanczos,\"\n            f\"zoompan=z='{zoom_curve}':d=180:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)':s={w}x{h},\"\n            f\"vignette=PI/6\"\n        )\n        \n        if subtitle_path and os.path.exists(subtitle_path):\n            abs_sub = os.path.abspath(subtitle_path).replace('\\\\', '/').replace(':', '\\\\:')\n            abs_fonts = os.path.abspath(FONT_DIR).replace('\\\\', '/').replace(':', '\\\\:')\n            filter_chain += f\",subtitles='{abs_sub}':fontsdir='{abs_fonts}'\"\n        \n        filter_chain += \",fps=30\"\n        \n        cmd = [\n            \"ffmpeg\", \"-y\", \"-loop\", \"1\", \"-i\", img_path, \"-t\", \"6\",\n            \"-vf\", filter_chain, \"-c:v\", \"libx264\", \"-preset\", \"ultrafast\",\n            \"-crf\", \"23\", \"-maxrate\", \"10M\", \"-bufsize\", \"20M\",\n            \"-pix_fmt\", \"yuv420p\", \"-threads\", \"8\", vid_path\n        ]\n\n        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n        \n        if os.path.exists(vid_path):\n            with open(vid_path, \"rb\") as f:\n                return f.read()\n        return None\n    except Exception as e:\n        print(f\"Error in image_to_video_clip: {e}\")\n        return None\n    finally:\n        if os.path.exists(img_path): os.remove(img_path)\n        if os.path.exists(vid_path): os.remove(vid_path)\n\ndef load_engine(device_id):\n    print(f\"‚è≥ Loading SDXL on GPU {device_id}...\")\n    pipe = StableDiffusionXLPipeline.from_pretrained(\n        \"SG161222/RealVisXL_V4.0_Lightning\",\n        torch_dtype=torch.float16,\n        variant=\"fp16\"\n    ).to(f\"cuda:{device_id}\")\n    \n    pipe.unet.to(memory_format=torch.channels_last)\n    try:\n        pipe.enable_xformers_memory_efficient_attention()\n    except: pass\n    \n    pipe.vae = AutoencoderTiny.from_pretrained(\"madebyollin/taesdxl\", torch_dtype=torch.float16).to(f\"cuda:{device_id}\")\n\n    pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n    pipe.set_progress_bar_config(disable=True)\n    return pipe\n\npipelines = []\nif GPU_COUNT > 0:\n    for i in range(GPU_COUNT):\n        pipelines.append(load_engine(i))\n\ndef get_safe_resolution(aspect_ratio_name):\n    # EXTREME SPEED SETTINGS (6s)\n    if aspect_ratio_name == \"16:9\": return (1152, 640, 1920, 1080)\n    elif aspect_ratio_name == \"9:16\": return (640, 1152, 1080, 1920)\n    elif aspect_ratio_name == \"4:5\": return (896, 1088, 1080, 1350)\n    elif aspect_ratio_name == \"16:7\": return (1152, 512, 1920, 840)\n    else: return (1024, 1024, 1024, 1024)\n\ndef gpu_worker(gpu_id, pipeline, task_queue):\n    while True:\n        try:\n            task = task_queue.get(timeout=0.05)\n            neg = \"bad anatomy, bad hands, missing fingers, extra fingers, three hands, three legs, bad arms, missing legs, missing arms, poorly drawn face, bad face, fused face, cloned face, three crus, fused feet, fused thigh, extra crus, ugly, gross, sloppy, messy, blurry, low quality, duplicate, distortion, mutation, double head\"\n            image = pipeline(task['prompt'], num_inference_steps=STEPS, guidance_scale=GUIDANCE_SCALE, width=task['ai_width'], height=task['ai_height'], negative_prompt=neg).images[0]\n            \n            # Pass everything to post-processing queue\n            video_process_queue.put({'image': image, 'task': task})\n            task_queue.task_done()\n        except queue.Empty:\n            continue\n\ndef cpu_video_worker():\n    while True:\n        try:\n            item = video_process_queue.get(timeout=0.05)\n            image = item['image']\n            task = item['task']\n            job_id = task['job_id']\n            start_time = task.get('start_time', time.time())\n            \n            # --- SUBTITLES ---\n            subtitle_path = None\n            if 'subtitle_data' in task and task['subtitle_data']:\n                try:\n                    unique_sub_id = str(uuid.uuid4())\n                    temp_ass_path = f\"temp_{unique_sub_id}.ass\"\n                    success = generate_clip_ass_subtitles(task['subtitle_data'], task['final_width'], task['final_height'], temp_ass_path)\n                    if success:\n                        subtitle_path = temp_ass_path\n                except Exception as e:\n                    print(f\"Subtitle gen failed: {e}\")\n            \n            # --- RENDER VIDEO ---\n            video_bytes = image_to_video_clip(image, target_width=task['final_width'], target_height=task['final_height'], subtitle_path=subtitle_path)\n            \n            if subtitle_path and os.path.exists(subtitle_path):\n                os.remove(subtitle_path)\n            \n            if video_bytes:\n                size_mb = len(video_bytes) / (1024 * 1024)\n                r2_url = upload_to_r2(video_bytes, job_id)\n                \n                gen_time = time.time() - start_time\n                \n                # --- UPDATE REDIS HERE (ASYNC FROM MAIN THREAD) ---\n                if r2_url:\n                    result_data = json.dumps({\"r2_url\": r2_url, \"time\": str(gen_time), \"size_mb\": str(size_mb), \"job_id\": job_id})\n                    redis_client.set(f\"completed:{job_id}\", result_data, ex=3600)\n                    print(f\"‚úÖ [VIDEO] Done! ‚è±Ô∏è {gen_time:.1f}s | üíæ {size_mb:.1f}MB\")\n                else:\n                    redis_client.set(f\"failed:{job_id}\", \"Upload failed\", ex=3600)\n            \n            video_process_queue.task_done()\n        except queue.Empty:\n            continue\n        except Exception as e:\n            print(f\"CPU Worker Error: {e}\")\n\nfor i, pipe in enumerate(pipelines):\n    threading.Thread(target=gpu_worker, args=(i, pipe, gpu_queues[i]), daemon=True).start()\n\nfor _ in range(8):\n    threading.Thread(target=cpu_video_worker, daemon=True).start()\n\ndef dispatch_video_job(job_key, job_data, gpu_id):\n    \"\"\"\n    NON-BLOCKING dispatch function.\n    Prepares the job and pushes it to the GPU queue.\n    Returns True if dispatched, False if error.\n    \"\"\"\n    try:\n        job = json.loads(job_data)\n        job_id = job['job_id']\n        prompt = job['prompt']\n        ratio = job['ratio']\n        subtitle_data = job.get('subtitle_data', [])\n        \n        ai_w, ai_h, final_w, final_h = get_safe_resolution(ratio)\n        \n        # Smart Truncate\n        safe_prompt = prompt[:180] \n        full_prompt = f\"{safe_prompt}, 8k, masterpiece, highly detailed, cinematic lighting\"\n        \n        task = {\n            'job_id': job_id, \n            'prompt': full_prompt, \n            'ai_width': ai_w, \n            'ai_height': ai_h, \n            'final_width': final_w, \n            'final_height': final_h, \n            'subtitle_data': subtitle_data,\n            'start_time': time.time() # Track start time here\n        }\n        \n        # Fire and forget!\n        gpu_queues[gpu_id].put(task)\n        return True\n        \n    except Exception as e:\n        print(f\"‚ùå Dispatch Failed: {e}\")\n        redis_client.set(f\"failed:{job.get('job_id', 'unknown')}\", str(e), ex=3600)\n        return False\n\n# ------------------------------------------\n# MAIN LOOP\n# ------------------------------------------\ndef main():\n    print(\"\\n\" + \"=\"*60)\n    print(f\"üöÄ GPU SERVER {SERVER_ID} - READY (PARALLEL MODE)\")\n    print(\"=\"*60)\n    print(f\"‚úÖ GPUs: {GPU_COUNT}\")\n    print(f\"‚úÖ R2: {R2_BUCKET_NAME}\")\n    print(f\"‚úÖ Redis: {UPSTASH_REDIS_REST_URL.split('//')[1].split('.')[0]}\")\n    print(f\"‚úÖ Whisper: Loaded on GPU\")\n    print(f\"‚úÖ Fonts: Loaded for Multilingual Support\")\n    print(f\"üî• TRANSCRIPTION HAS HIGHEST PRIORITY\")\n    print(\"=\"*60 + \"\\n\")\n    \n    processed = 0\n    gpu_rr = 0\n    \n    while True:\n        # ‚úÖ DUAL AUTO-SHUTDOWN CHECK (3:30 PM & 11:00 PM IST)\n        now_utc = datetime.now(timezone.utc)\n        now_ist = now_utc + timedelta(hours=5, minutes=30)\n        \n        is_time1 = (now_ist.hour == 15 and now_ist.minute == 30)\n        is_time2 = (now_ist.hour == 23 and now_ist.minute == 0)\n        \n        if is_time1 or is_time2:\n            print(f\"\\nüõë Scheduled Shutdown: It is {now_ist.strftime('%I:%M %p')} IST. Terminating.\")\n            sys.exit(0)\n\n        try:\n            # 1. TRANSCRIPTION (Priority) - Still sequential usually best for stability\n            transcribe_keys = redis_client.keys(\"transcribe_pending:*\")\n            if transcribe_keys:\n                print(f\"\\nüî• PRIORITY: Found {len(transcribe_keys)} transcription job(s)\")\n                for job_key in transcribe_keys:\n                    job_data = redis_client.get(job_key)\n                    if job_data:\n                        # We delete immediately to avoid re-reading, \n                        # logic inside process_transcription_job handles success/fail updates\n                        # But process_transcription_job currently deletes at end. \n                        # Since transcription is fast/CPU/GPU hybrid and sequential here, we leave it blocking for safety.\n                        process_transcription_job(job_key, job_data)\n                        processed += 1\n                continue\n            \n            # 2. VIDEO GENERATION (True Parallel)\n            pending_keys = redis_client.keys(\"pending:*\")\n            if pending_keys:\n                for job_key in pending_keys:\n                    job_data = redis_client.get(job_key)\n                    if job_data:\n                        # Pick GPU\n                        gpu_id = gpu_rr % len(pipelines)\n                        gpu_rr += 1\n                        \n                        # Dispatch\n                        if dispatch_video_job(job_key, job_data, gpu_id):\n                            # IMPORTANT: Delete from 'pending' immediately so main loop \n                            # doesn't pick it up again while GPU is working.\n                            redis_client.delete(job_key)\n                            processed += 1\n            \n            time.sleep(0.1) # Faster loop for responsiveness\n            \n        except KeyboardInterrupt:\n            print(\"\\nüõë Shutting down...\")\n            break\n        except Exception as e:\n            print(f\"‚ùå Error: {e}\")\n            time.sleep(5)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}